{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4368115,"sourceType":"datasetVersion","datasetId":1152384}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:51:59.011978Z","iopub.execute_input":"2024-12-03T14:51:59.012640Z","iopub.status.idle":"2024-12-03T14:51:59.993416Z","shell.execute_reply.started":"2024-12-03T14:51:59.012593Z","shell.execute_reply":"2024-12-03T14:51:59.992394Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"/kaggle/input/cyberbullying-dataset/twitter_sexism_parsed_dataset.csv\n/kaggle/input/cyberbullying-dataset/youtube_parsed_dataset.csv\n/kaggle/input/cyberbullying-dataset/kaggle_parsed_dataset.csv\n/kaggle/input/cyberbullying-dataset/aggression_parsed_dataset.csv\n/kaggle/input/cyberbullying-dataset/toxicity_parsed_dataset.csv\n/kaggle/input/cyberbullying-dataset/attack_parsed_dataset.csv\n/kaggle/input/cyberbullying-dataset/twitter_parsed_dataset.csv\n/kaggle/input/cyberbullying-dataset/twitter_racism_parsed_dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom transformers import GPT2Tokenizer\nimport tqdm\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:51:59.994752Z","iopub.execute_input":"2024-12-03T14:51:59.995147Z","iopub.status.idle":"2024-12-03T14:52:04.005166Z","shell.execute_reply.started":"2024-12-03T14:51:59.995118Z","shell.execute_reply":"2024-12-03T14:52:04.004494Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"aggression_df = pd.read_csv(\"/kaggle/input/cyberbullying-dataset/aggression_parsed_dataset.csv\")\nattack_df = pd.read_csv(\"/kaggle/input/cyberbullying-dataset/attack_parsed_dataset.csv\")\nkaggle_df = pd.read_csv(\"/kaggle/input/cyberbullying-dataset/kaggle_parsed_dataset.csv\")\ntoxicity_df = pd.read_csv(\"/kaggle/input/cyberbullying-dataset/toxicity_parsed_dataset.csv\")\ntwitter_parsed_df = pd.read_csv(\"/kaggle/input/cyberbullying-dataset/twitter_parsed_dataset.csv\")\ntwitter_racism_df = pd.read_csv(\"/kaggle/input/cyberbullying-dataset/twitter_racism_parsed_dataset.csv\")\ntwitter_sexism_df  = pd.read_csv(\"/kaggle/input/cyberbullying-dataset/twitter_sexism_parsed_dataset.csv\")\nyoutube_df = pd.read_csv(\"/kaggle/input/cyberbullying-dataset/youtube_parsed_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:04.006017Z","iopub.execute_input":"2024-12-03T14:52:04.006434Z","iopub.status.idle":"2024-12-03T14:52:08.312829Z","shell.execute_reply.started":"2024-12-03T14:52:04.006407Z","shell.execute_reply":"2024-12-03T14:52:08.312088Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"count_ones = aggression_df['oh_label'][aggression_df['oh_label'] == 1].value_counts()\ncount_zeros =  aggression_df['oh_label'][aggression_df['oh_label'] == 0].value_counts()\nprint(count_ones)\nprint(\"---\")\nprint(count_zeros)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:08.314518Z","iopub.execute_input":"2024-12-03T14:52:08.314799Z","iopub.status.idle":"2024-12-03T14:52:08.332880Z","shell.execute_reply.started":"2024-12-03T14:52:08.314772Z","shell.execute_reply":"2024-12-03T14:52:08.331997Z"}},"outputs":[{"name":"stdout","text":"oh_label\n1    14782\nName: count, dtype: int64\n---\noh_label\n0    101082\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Concatonate dataframes by extracting relevant columns\ndf = [\n    aggression_df[[\"Text\", \"oh_label\"]], \n    attack_df[[\"Text\", \"oh_label\"]],\n    kaggle_df[[\"Text\", \"oh_label\"]],\n    toxicity_df[[\"Text\", \"oh_label\"]],\n    twitter_parsed_df[[\"Text\", \"oh_label\"]],\n    twitter_racism_df[[\"Text\", \"oh_label\"]],\n    twitter_sexism_df[[\"Text\", \"oh_label\"]],\n    youtube_df[[\"Text\", \"oh_label\"]]\n]\n\ncomb_df = pd.concat(df, ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:08.333933Z","iopub.execute_input":"2024-12-03T14:52:08.334204Z","iopub.status.idle":"2024-12-03T14:52:08.383035Z","shell.execute_reply.started":"2024-12-03T14:52:08.334180Z","shell.execute_reply":"2024-12-03T14:52:08.382414Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"count_ones = comb_df['oh_label'][comb_df['oh_label'] == 1].value_counts()\ncount_zeros = comb_df['oh_label'][comb_df['oh_label'] == 0].value_counts()\nprint(count_ones)\nprint(\"---\")\nprint(count_zeros)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:08.383856Z","iopub.execute_input":"2024-12-03T14:52:08.384098Z","iopub.status.idle":"2024-12-03T14:52:08.410506Z","shell.execute_reply.started":"2024-12-03T14:52:08.384043Z","shell.execute_reply":"2024-12-03T14:52:08.409721Z"}},"outputs":[{"name":"stdout","text":"oh_label\n1.0    57651\nName: count, dtype: int64\n---\noh_label\n0.0    391223\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"required_sent_num_0 = 15_000\nrequired_sent_num_1 = 15_000\n\noh_label_0_sample = comb_df[comb_df['oh_label'] == 0].sample(n=required_sent_num_0, random_state=42)\noh_label_1_sample = comb_df[comb_df['oh_label'] == 1].sample(n=required_sent_num_1, random_state=42)\n\n# Combine the two subsets\nprefered_df = pd.concat([oh_label_0_sample, oh_label_1_sample], ignore_index=True)\n\n# Shuffle the resulting dataframe \nprefered_df = prefered_df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:08.411403Z","iopub.execute_input":"2024-12-03T14:52:08.411670Z","iopub.status.idle":"2024-12-03T14:52:08.470410Z","shell.execute_reply.started":"2024-12-03T14:52:08.411645Z","shell.execute_reply":"2024-12-03T14:52:08.469559Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"prefered_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:08.471528Z","iopub.execute_input":"2024-12-03T14:52:08.471858Z","iopub.status.idle":"2024-12-03T14:52:08.485605Z","shell.execute_reply.started":"2024-12-03T14:52:08.471822Z","shell.execute_reply":"2024-12-03T14:52:08.484862Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                    Text  oh_label\n0       :Believe the protection had better stay indef...       0.0\n1      @Qoloob4 @Vandaliser @sajid_fairooz @IsraeliRe...       1.0\n2      RT @pdemmett: Why do film bosses have to make ...       1.0\n3        You piece of shit fucking block me then puss...       1.0\n4         ==SimCopter Shenanigans== Hiya. I originall...       0.0\n...                                                  ...       ...\n29995    == Fuck you ==  Fuck you shit asshole! You a...       1.0\n29996           Yeah his headstock is just upside down         0.0\n29997    you are correct. If you look at who created ...       0.0\n29998                 Also, my mother is a prostitute.         1.0\n29999    == Afraid of the competition with the pussy ...       1.0\n\n[30000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>oh_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>:Believe the protection had better stay indef...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Qoloob4 @Vandaliser @sajid_fairooz @IsraeliRe...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @pdemmett: Why do film bosses have to make ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You piece of shit fucking block me then puss...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>==SimCopter Shenanigans== Hiya. I originall...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>== Fuck you ==  Fuck you shit asshole! You a...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>Yeah his headstock is just upside down</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>you are correct. If you look at who created ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>Also, my mother is a prostitute.</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>== Afraid of the competition with the pussy ...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"count_ones = prefered_df['oh_label'][prefered_df['oh_label']==1].count()\ncount_zeros = prefered_df['oh_label'][prefered_df['oh_label']==0].count()\n\nprint(count_ones, count_zeros)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:08.486519Z","iopub.execute_input":"2024-12-03T14:52:08.486768Z","iopub.status.idle":"2024-12-03T14:52:08.492975Z","shell.execute_reply.started":"2024-12-03T14:52:08.486743Z","shell.execute_reply":"2024-12-03T14:52:08.492207Z"}},"outputs":[{"name":"stdout","text":"15000 15000\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Clean the Text\nimport re\n\ndef clean_text(text):\n    # Remove URLs\n    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n    # Remove mentions and hashtags\n    text = re.sub(r'\\@\\w+|\\#', '', text)\n    # Remove contractions and special characters\n    pattern = r\"'s|'t|'re|'ve|'m|'ll|'d|[^a-zA-Z0-9\\s]+|\\s+\"\n    text = re.sub(pattern, \" \", text)\n    return text.lower().strip()\n\nprefered_df['Cleaned_text'] = prefered_df['Text'].apply(clean_text) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:08.495175Z","iopub.execute_input":"2024-12-03T14:52:08.495417Z","iopub.status.idle":"2024-12-03T14:52:09.652649Z","shell.execute_reply.started":"2024-12-03T14:52:08.495393Z","shell.execute_reply":"2024-12-03T14:52:09.651958Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"prefered_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:09.653734Z","iopub.execute_input":"2024-12-03T14:52:09.654101Z","iopub.status.idle":"2024-12-03T14:52:09.664528Z","shell.execute_reply.started":"2024-12-03T14:52:09.654047Z","shell.execute_reply":"2024-12-03T14:52:09.663725Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                    Text  oh_label  \\\n0       :Believe the protection had better stay indef...       0.0   \n1      @Qoloob4 @Vandaliser @sajid_fairooz @IsraeliRe...       1.0   \n2      RT @pdemmett: Why do film bosses have to make ...       1.0   \n3        You piece of shit fucking block me then puss...       1.0   \n4         ==SimCopter Shenanigans== Hiya. I originall...       0.0   \n...                                                  ...       ...   \n29995    == Fuck you ==  Fuck you shit asshole! You a...       1.0   \n29996           Yeah his headstock is just upside down         0.0   \n29997    you are correct. If you look at who created ...       0.0   \n29998                 Also, my mother is a prostitute.         1.0   \n29999    == Afraid of the competition with the pussy ...       1.0   \n\n                                            Cleaned_text  \n0      believe the protection had better stay indefin...  \n1      which is why he gave himself as many wives as ...  \n2      rt   why do film bosses have to make life weir...  \n3      you piece of shit fucking block me then pussy ...  \n4      simcopter shenanigans  hiya  i originally foll...  \n...                                                  ...  \n29995  fuck you   fuck you shit asshole  you are a pi...  \n29996             yeah his headstock is just upside down  \n29997  you are correct  if you look at who created th...  \n29998                    also  my mother is a prostitute  \n29999  afraid of the competition with the pussy pass ...  \n\n[30000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>oh_label</th>\n      <th>Cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>:Believe the protection had better stay indef...</td>\n      <td>0.0</td>\n      <td>believe the protection had better stay indefin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Qoloob4 @Vandaliser @sajid_fairooz @IsraeliRe...</td>\n      <td>1.0</td>\n      <td>which is why he gave himself as many wives as ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @pdemmett: Why do film bosses have to make ...</td>\n      <td>1.0</td>\n      <td>rt   why do film bosses have to make life weir...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You piece of shit fucking block me then puss...</td>\n      <td>1.0</td>\n      <td>you piece of shit fucking block me then pussy ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>==SimCopter Shenanigans== Hiya. I originall...</td>\n      <td>0.0</td>\n      <td>simcopter shenanigans  hiya  i originally foll...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>== Fuck you ==  Fuck you shit asshole! You a...</td>\n      <td>1.0</td>\n      <td>fuck you   fuck you shit asshole  you are a pi...</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>Yeah his headstock is just upside down</td>\n      <td>0.0</td>\n      <td>yeah his headstock is just upside down</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>you are correct. If you look at who created ...</td>\n      <td>0.0</td>\n      <td>you are correct  if you look at who created th...</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>Also, my mother is a prostitute.</td>\n      <td>1.0</td>\n      <td>also  my mother is a prostitute</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>== Afraid of the competition with the pussy ...</td>\n      <td>1.0</td>\n      <td>afraid of the competition with the pussy pass ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    prefered_df['Cleaned_text'], prefered_df['oh_label'], test_size=0.2,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:09.665657Z","iopub.execute_input":"2024-12-03T14:52:09.666506Z","iopub.status.idle":"2024-12-03T14:52:10.257580Z","shell.execute_reply.started":"2024-12-03T14:52:09.666480Z","shell.execute_reply":"2024-12-03T14:52:10.256849Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_texts.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:10.258549Z","iopub.execute_input":"2024-12-03T14:52:10.258928Z","iopub.status.idle":"2024-12-03T14:52:10.265116Z","shell.execute_reply.started":"2024-12-03T14:52:10.258901Z","shell.execute_reply":"2024-12-03T14:52:10.264358Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"21753    what identity is that  dracula  why is it that...\n251      dude  i do it because your mum screams tooooo ...\n22941    windows product activation suggestions   hi  i...\n618      i  only talking about this quote  although oth...\n17090    strategy toolkit  strategy toolkit has been no...\nName: Cleaned_text, dtype: object"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\n\n# Load the tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\n# Assign a padding token\ntokenizer.pad_token = tokenizer.eos_token \n\n# Tokenize the Texts\ntrain_encodings = tokenizer(\n    list(train_texts), \n    truncation=True,\n    padding=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\nval_encodings = tokenizer(\n    list(val_texts), \n    truncation=True,\n    padding=True, \n    max_length=256, \n    return_tensors='pt'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:10.266153Z","iopub.execute_input":"2024-12-03T14:52:10.266468Z","iopub.status.idle":"2024-12-03T14:52:25.890790Z","shell.execute_reply.started":"2024-12-03T14:52:10.266430Z","shell.execute_reply":"2024-12-03T14:52:25.890045Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31f2494d36624266a44ee82dda127c11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"043b7d21dfed41eb8e89b2b72a9cb41d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44607f874b6647c49f00aea0a6ddf100"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e0384ceca284a6ca2cfcf2a19d6ba99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"189d508829704a7eb18fa96ec152afd8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:25.891754Z","iopub.execute_input":"2024-12-03T14:52:25.892187Z","iopub.status.idle":"2024-12-03T14:52:25.895934Z","shell.execute_reply.started":"2024-12-03T14:52:25.892160Z","shell.execute_reply":"2024-12-03T14:52:25.895182Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Creating Custom datasets\n\nclass SentimentAnalysis(Dataset):\n    \n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n        \n    def __len__(self):\n        return len(self.labels)\n        \n    def __getitem__(self, idx):\n        # Fetch the encoding for the given index\n        item = {key: val[idx].clone() for key, val in self.encodings.items()}\n        # Fetch the label for the given index\n        label = torch.tensor(self.labels[idx])  # Convert the label to a tensor\n        return item, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:25.896794Z","iopub.execute_input":"2024-12-03T14:52:25.896992Z","iopub.status.idle":"2024-12-03T14:52:25.907526Z","shell.execute_reply.started":"2024-12-03T14:52:25.896972Z","shell.execute_reply":"2024-12-03T14:52:25.906903Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Create dataset \ntrain_data = SentimentAnalysis(train_encodings, list(train_labels))\nval_data = SentimentAnalysis(val_encodings, list(val_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:25.908610Z","iopub.execute_input":"2024-12-03T14:52:25.908926Z","iopub.status.idle":"2024-12-03T14:52:25.918893Z","shell.execute_reply.started":"2024-12-03T14:52:25.908891Z","shell.execute_reply":"2024-12-03T14:52:25.918183Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import GPT2Config, GPT2Model\n\n# Load GPT-2 configuration\nconfig = GPT2Config.from_pretrained('gpt2')\nconfig.num_labels = 2  # For binary classification\n\n# Define the custom model class\nclass GPTForSentiment(nn.Module):\n    def __init__(self, config):\n        super(GPTForSentiment, self).__init__()\n        self.gpt2 = GPT2Model.from_pretrained('gpt2', config=config)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)  # Classification Layer\n        \n    def forward(self, input_ids, attention_mask):\n        outputs = self.gpt2(input_ids=input_ids, attention_mask=attention_mask)\n        # Use the last hidden state from the last token for classification\n        logits = self.classifier(outputs.last_hidden_state[:, -1, :])\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:25.919846Z","iopub.execute_input":"2024-12-03T14:52:25.920188Z","iopub.status.idle":"2024-12-03T14:52:26.454733Z","shell.execute_reply.started":"2024-12-03T14:52:25.920148Z","shell.execute_reply":"2024-12-03T14:52:26.454056Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"model = GPTForSentiment(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:26.455644Z","iopub.execute_input":"2024-12-03T14:52:26.455956Z","iopub.status.idle":"2024-12-03T14:52:28.966284Z","shell.execute_reply.started":"2024-12-03T14:52:26.455933Z","shell.execute_reply":"2024-12-03T14:52:28.965525Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00aeefdb8eb246e4a31796cdef83aa5a"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# set up dataloaders\ntrain_loader = DataLoader(train_data, batch_size=8, shuffle=True, drop_last=True)\nval_loader = DataLoader(val_data, batch_size=8)\n\n# Model Parameters\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-05)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:28.967377Z","iopub.execute_input":"2024-12-03T14:52:28.967724Z","iopub.status.idle":"2024-12-03T14:52:29.357031Z","shell.execute_reply.started":"2024-12-03T14:52:28.967684Z","shell.execute_reply":"2024-12-03T14:52:29.356340Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:29.358123Z","iopub.execute_input":"2024-12-03T14:52:29.358646Z","iopub.status.idle":"2024-12-03T14:52:29.778952Z","shell.execute_reply.started":"2024-12-03T14:52:29.358609Z","shell.execute_reply":"2024-12-03T14:52:29.778113Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"GPTForSentiment(\n  (gpt2): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, accuracy_score\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:42.848831Z","iopub.execute_input":"2024-12-03T14:52:42.849202Z","iopub.status.idle":"2024-12-03T14:52:42.853288Z","shell.execute_reply.started":"2024-12-03T14:52:42.849169Z","shell.execute_reply":"2024-12-03T14:52:42.852469Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Training method and loop\ndef train_fn(train_dataloader, epochs, model, loss_fn, optimizer, device):\n    model.to(device)  # Move model to device (CPU or GPU)\n\n    for epoch in range(epochs):  # Fixed missing closing parenthesis\n        model.train()  # Ensure the model is in training mode\n        \n        loop = tqdm(train_dataloader, leave=True)\n        all_preds_train = []\n        all_labels_train = []\n        all_preds_labels_train = []  # To store predicted labels for accuracy calculation\n        \n        for batch in loop: \n            \n            inputs, labels = batch\n            # Move inputs and labels to the device\n            if isinstance(inputs, dict):\n                inputs = {key: val.to(device) for key, val in inputs.items()}\n                attention_mask = inputs.get('attention_mask')  # Extract the attention mask if present\n            else: \n                inputs = inputs.to(device)\n                attention_mask = None  # No attention mask if not present\n            labels = labels.to(device)\n            labels = labels.long()\n\n            optimizer.zero_grad()\n            \n            # Pass attention_mask only if it exists\n            if attention_mask is not None:\n                outputs = model(inputs['input_ids'], attention_mask=attention_mask)\n            else:\n                outputs = model(inputs)\n                \n            # Compute the loss\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            # Convert logits to probabilities (if applicable)\n            probs = torch.softmax(outputs, dim=1)\n            preds = probs[:, 1]  # Get probability for the positive class\n            \n            # Convert probabilities to class predictions (0 or 1)\n            preds_class = (preds > 0.5).long()  # Threshold at 0.5\n            \n            # Store predictions and labels for AUC and accuracy\n            all_preds_train.extend(preds.detach().cpu().numpy())\n            all_labels_train.extend(labels.cpu().numpy())\n            all_preds_labels_train.extend(preds_class.cpu().numpy())\n            \n            # Update progress bar\n            loop.set_description(f'Epoch {epoch}')\n            loop.set_postfix(loss=loss.item())\n        \n        # Calculate training AUC after the epoch\n        train_auc = roc_auc_score(all_labels_train, all_preds_train)\n        train_accuracy = accuracy_score(all_labels_train, all_preds_labels_train)  # Calculate accuracy\n        print(f\"Epoch {epoch} - Training AUC: {train_auc:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:43.413997Z","iopub.execute_input":"2024-12-03T14:52:43.414382Z","iopub.status.idle":"2024-12-03T14:52:43.423324Z","shell.execute_reply.started":"2024-12-03T14:52:43.414352Z","shell.execute_reply":"2024-12-03T14:52:43.422402Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_fn(train_loader, 6, model, loss_fn, optimizer, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T14:52:44.176807Z","iopub.execute_input":"2024-12-03T14:52:44.177391Z","iopub.status.idle":"2024-12-03T16:59:28.662287Z","shell.execute_reply.started":"2024-12-03T14:52:44.177358Z","shell.execute_reply":"2024-12-03T16:59:28.661417Z"}},"outputs":[{"name":"stderr","text":"Epoch 0: 100%|██████████| 3000/3000 [21:03<00:00,  2.37it/s, loss=0.24]   \n","output_type":"stream"},{"name":"stdout","text":"Epoch 0 - Training AUC: 0.9382, Training Accuracy: 0.8654\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 3000/3000 [21:07<00:00,  2.37it/s, loss=0.35]   \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Training AUC: 0.9686, Training Accuracy: 0.9118\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 3000/3000 [21:08<00:00,  2.37it/s, loss=0.0967]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Training AUC: 0.9843, Training Accuracy: 0.9427\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 3000/3000 [21:07<00:00,  2.37it/s, loss=0.0899]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Training AUC: 0.9931, Training Accuracy: 0.9656\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 3000/3000 [21:08<00:00,  2.37it/s, loss=0.0615]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Training AUC: 0.9966, Training Accuracy: 0.9779\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 3000/3000 [21:08<00:00,  2.36it/s, loss=0.003]   ","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Training AUC: 0.9981, Training Accuracy: 0.9826\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Validation Function\ndef validate_fn(val_dataloader, model):\n    model.eval()  # Ensure the model is in evaluation mode\n    \n    all_preds_val = []\n    all_labels_val = []\n    with torch.no_grad():  # Disable gradient calculations for validation\n        for batch in val_dataloader:\n            inputs, labels = batch\n            \n            # Move inputs and labels to device\n            if isinstance(inputs, dict):  # For tokenized inputs\n                inputs = {key: val.to(device) for key, val in inputs.items()}\n                attention_mask = inputs.get('attention_mask')  # Extract attention_mask if present\n            else:  # For simple tensors\n                inputs = inputs.to(device)\n                attention_mask = None  # No attention mask available\n            labels = labels.to(device)\n\n            # Pass attention_mask only if it exists\n            if attention_mask is not None:\n                outputs = model(inputs['input_ids'], attention_mask=attention_mask)\n            else:\n                outputs = model(inputs)\n            \n            # Convert logits to probabilities (if applicable)\n            probs = torch.softmax(outputs, dim=1)\n            preds = probs[:, 1]  # Get probability for the positive class\n            \n            # Store for AUC\n            all_preds_val.extend(preds.cpu().numpy())\n            all_labels_val.extend(labels.cpu().numpy())\n    # Calculate validation AUC\n    val_auc = roc_auc_score(all_labels_val, all_preds_val)\n    print(f\"Validation AUC: {val_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:00:29.075572Z","iopub.execute_input":"2024-12-03T17:00:29.076264Z","iopub.status.idle":"2024-12-03T17:00:29.083408Z","shell.execute_reply.started":"2024-12-03T17:00:29.076232Z","shell.execute_reply":"2024-12-03T17:00:29.082488Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"validate_fn(val_loader, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:00:59.907774Z","iopub.execute_input":"2024-12-03T17:00:59.908126Z","iopub.status.idle":"2024-12-03T17:02:42.250017Z","shell.execute_reply.started":"2024-12-03T17:00:59.908086Z","shell.execute_reply":"2024-12-03T17:02:42.249087Z"}},"outputs":[{"name":"stdout","text":"Validation AUC: 0.9586\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\n\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")  # Use the correct tokenizer\n# Add a custom pad token if not already defined\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\n# Update the model's tokenizer settings\ntokenizer.pad_token = '[PAD]'\n\ndef preprocess_input(sentence):\n    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    return inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:03:15.205891Z","iopub.execute_input":"2024-12-03T17:03:15.206586Z","iopub.status.idle":"2024-12-03T17:03:15.426157Z","shell.execute_reply.started":"2024-12-03T17:03:15.206554Z","shell.execute_reply":"2024-12-03T17:03:15.425211Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef test_sentence(sentence):\n    # Preprocess the input sentence\n    inputs = preprocess_input(sentence)\n\n    # Move inputs to the same device as the model (if you are using a GPU)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    inputs = {key: val.to(device) for key, val in inputs.items()}\n    model.to(device)\n\n    # Run the sentence through the model\n    with torch.no_grad():  # Disable gradients for inference\n        outputs = model(**inputs)\n    print(outputs)\n\n    # Get the logits (raw predictions)\n    logits = outputs\n\n    # Convert logits to probabilities using softmax\n    probabilities = F.softmax(logits, dim=1)\n\n    # Get predicted class (1 for cyberbullying, 0 for non-cyberbullying)\n    predicted_class = torch.argmax(probabilities, dim=1).item()\n\n    # Print the result\n    if predicted_class == 0:\n        print(f\"The sentence is classified as: Not Cyberbullying\")\n    else:\n        print(f\"The sentence is classified as: Cyberbullying\")\n\n    return predicted_class, probabilities\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:03:27.216840Z","iopub.execute_input":"2024-12-03T17:03:27.217278Z","iopub.status.idle":"2024-12-03T17:03:27.223604Z","shell.execute_reply.started":"2024-12-03T17:03:27.217248Z","shell.execute_reply":"2024-12-03T17:03:27.222699Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sentence = \"You must have small penis\"\n\npredicted_class, probabilities = test_sentence(sentence)\n\n# Output the predicted class and probabilities\nprint(f\"Predicted Class: {predicted_class}\")  # 0 = Non-Cyberbullying, 1 = Cyberbullying\nprint(f\"Probabilities: {probabilities}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:07:37.677634Z","iopub.execute_input":"2024-12-03T17:07:37.678401Z","iopub.status.idle":"2024-12-03T17:07:37.698232Z","shell.execute_reply.started":"2024-12-03T17:07:37.678369Z","shell.execute_reply":"2024-12-03T17:07:37.697411Z"}},"outputs":[{"name":"stdout","text":"tensor([[-0.1155,  0.0071]], device='cuda:0')\nThe sentence is classified as: Cyberbullying\nPredicted Class: 1\nProbabilities: tensor([[0.4694, 0.5306]], device='cuda:0')\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}